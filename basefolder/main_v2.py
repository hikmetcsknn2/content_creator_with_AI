from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
import google.generativeai as genai
import markdown
import os
from datetime import datetime
from dotenv import load_dotenv
from .models_v2 import Base, ContentConfig

# .env dosyasÄ±nÄ± BOM ile okuma sorununu Ã§Ã¶z
env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
if os.path.exists(env_path):
    with open(env_path, 'r', encoding='utf-8-sig') as f:  # utf-8-sig BOM'u otomatik kaldÄ±rÄ±r
        content = f.read().strip()
        print(f"ğŸ“„ .env iÃ§eriÄŸi: {repr(content)}")
        
        # Manuel olarak environment variable'a ekle
        if '=' in content:
            key, value = content.split('=', 1)
            key = key.strip()
            value = value.strip()
            os.environ[key] = value
            print(f"âœ… Manuel olarak eklendi: {key} = {value[:10]}...")

# API key'i al
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEY environment variable bulunamadÄ±! .env dosyasÄ±nda tanÄ±mlayÄ±n.")

print(f"âœ… GEMINI_API_KEY yÃ¼klendi: {api_key[:10]}...")
genai.configure(api_key=api_key)

# FastAPI app
app = FastAPI(title="Content Assistant V2", version="2.0.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Database
DATABASE_URL = "sqlite:///./content_assistant_v2.db"
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Gemini AI - API key'i environment variable'dan al
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY environment variable bulunamadÄ±! .env dosyasÄ±nda tanÄ±mlayÄ±n.")

print(f"âœ… GEMINI_API_KEY yÃ¼klendi: {GEMINI_API_KEY[:10]}...")
genai.configure(api_key=GEMINI_API_KEY)

# Pydantic Models
class ContentGenerationRequest(BaseModel):
    content_type: str
    dynamic_data: dict = {}
    custom_ai_configs: dict = {}  # step_1, step_2 gibi Ã¶zel ayarlar iÃ§in
    custom_prompts: dict = {}  # step_1, step_2 gibi Ã¶zel prompt'lar iÃ§in

class ContentConfigCreate(BaseModel):
    content_type: str
    description: str = ""
    prompts: list  # [{"step": 1, "text": "...", "ai_settings": {...}}]

class ContentConfigResponse(BaseModel):
    id: int
    content_type: str
    description: str
    prompts: list
    created_at: datetime

class PromptTestRequest(BaseModel):
    prompt: str
    model: str = "gemini-2.5-flash"
    temperature: float = 0.7
    top_p: float = 0.7
    response_mime_type: str = "text/plain"
    max_tokens: int = 2000

# Helper Functions
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def apply_dynamic_data(text: str, dynamic_data: dict) -> str:
    """Dinamik verileri prompt'a uygula"""
    for key, value in dynamic_data.items():
        text = text.replace(f"{{{key}}}", str(value))
    return text

def generate_ai_content(prompt: str, ai_settings: dict) -> str:
    """AI ile iÃ§erik Ã¼ret"""
    try:
        print(f"ğŸ¤– AI ayarlarÄ±: {ai_settings}")
        print(f"ğŸ“ Prompt uzunluÄŸu: {len(prompt)} karakter")
        
        model = genai.GenerativeModel(ai_settings["model"])
        
        generation_config = {
            "temperature": ai_settings["temperature"],
            "top_p": ai_settings["top_p"],
            "response_mime_type": ai_settings["response_mime_type"]
        }
        
        # Token limitini kontrol et ve minimum 8192 yap
        max_tokens = ai_settings.get("max_tokens", 8192)
        if max_tokens < 8192:
            print(f"âš ï¸ Max tokens Ã§ok dÃ¼ÅŸÃ¼k ({max_tokens}), 8192'ye yÃ¼kseltiliyor")
            max_tokens = 8192
        
        generation_config["max_output_tokens"] = max_tokens
        print(f"ğŸ¯ Max tokens: {max_tokens}")
        
        print(f"âš™ï¸ Generation config: {generation_config}")
        
        response = model.generate_content(
            [prompt],
            generation_config=generation_config
        )
        
        # finish_reason kontrolÃ¼ - Ã¶nce kontrol et
        if response.candidates:
            candidate = response.candidates[0]
            finish_reason = candidate.finish_reason
            
            if finish_reason == 1:  # STOP - Normal
                return response.text if response.text else "BoÅŸ yanÄ±t alÄ±ndÄ±."
            elif finish_reason == 2:  # MAX_TOKENS - Token limiti
                return f"âš ï¸ Token limiti aÅŸÄ±ldÄ± (max_tokens: {ai_settings.get('max_tokens', 'belirtilmemiÅŸ')}). Limit artÄ±rÄ±n."
            elif finish_reason == 3:  # SAFETY
                return "âš ï¸ GÃ¼venlik filtresi: Prompt'u deÄŸiÅŸtirin."
            elif finish_reason == 4:  # RECITATION
                return "âš ï¸ Telif hakkÄ±: Ä°Ã§erik deÄŸiÅŸtirin."
            else:
                return f"âš ï¸ AI hatasÄ± (finish_reason: {finish_reason})"
        else:
            return "âš ï¸ AI yanÄ±tÄ± alÄ±namadÄ±."
            
    except Exception as e:
        return f"AI content generation failed: {str(e)}"

def markdown_to_html(text: str) -> str:
    """Markdown'Ä± HTML'e Ã§evir"""
    return markdown.markdown(text, extensions=['tables', 'fenced_code'])

# API Endpoints

@app.get("/")
async def root():
    return {"message": "Content Assistant V2 API", "version": "2.0.0"}

@app.get("/content-types")
async def list_content_types():
    """TÃ¼m konfigÃ¼rasyonlarÄ± listele - admin panel iÃ§in"""
    db = next(get_db())
    try:
        configs = db.query(ContentConfig).all()
        result = []
        for config in configs:
            result.append({
                "content_type": config.name,
                "prompt_count": len(config.prompts),
                "description": config.description
            })
        return result
    finally:
        db.close()

@app.get("/prompts/{content_type}")
async def get_prompts(content_type: str):
    """Belirli bir konfigÃ¼rasyonun prompt'larÄ±nÄ± getir"""
    db = next(get_db())
    try:
        config = db.query(ContentConfig).filter(ContentConfig.name == content_type).first()
        if not config:
            raise HTTPException(status_code=404, detail="KonfigÃ¼rasyon bulunamadÄ±")
        
        result = []
        for prompt_data in config.prompts:
            result.append({
                "prompt_key": f"{content_type}_prompt_{prompt_data['step']}",
                "step": prompt_data["step"],
                "content": prompt_data["text"],
                "ai_settings": prompt_data.get("ai_settings", {
                    "model": "gemini-2.5-flash",
                    "temperature": 0.7,
                    "top_p": 0.7,
                    "response_mime_type": "text/plain",
                    "max_tokens": 8192
                })
            })
        
        return {
            "content_type": content_type,
            "prompt_count": len(config.prompts),
            "prompts": result
        }
    finally:
        db.close()

@app.post("/generate-content")
async def generate_content(request: ContentGenerationRequest):
    """Ana iÃ§erik Ã¼retim endpoint'i"""
    db = next(get_db())
    
    try:
        print(f"ğŸ” Ä°Ã§erik tÃ¼rÃ¼ aranÄ±yor: {request.content_type}")
        print(f"ğŸ“Š Dinamik veriler: {request.dynamic_data}")
        print(f"âš™ï¸ Ã–zel AI config'ler: {request.custom_ai_configs}")
        
        # KonfigÃ¼rasyonu bul
        config = db.query(ContentConfig).filter(ContentConfig.name == request.content_type).first()
        if not config:
            print(f"âŒ KonfigÃ¼rasyon bulunamadÄ±: {request.content_type}")
            raise HTTPException(status_code=404, detail="KonfigÃ¼rasyon bulunamadÄ±")
        
        print(f"âœ… KonfigÃ¼rasyon bulundu: {config.name}")
        print(f"ğŸ“ Prompt sayÄ±sÄ±: {len(config.prompts)}")
        
        # Prompt'larÄ± iÅŸle
        results = []
        current_content = ""
        step_details = []  # Her step'in detaylarÄ±nÄ± sakla
        
        for prompt_data in config.prompts:
            step = prompt_data["step"]
            
            # Ã–zel prompt var mÄ± kontrol et
            if f"step_{step}" in request.custom_prompts:
                original_prompt = request.custom_prompts[f"step_{step}"]
                print(f"ğŸ”„ Ã–zel prompt kullanÄ±lÄ±yor - Step {step}: {original_prompt[:50]}...")
            else:
                original_prompt = prompt_data["text"]
                print(f"ğŸ”„ DB prompt kullanÄ±lÄ±yor - Step {step}: {original_prompt[:50]}...")
            
            # Dinamik verileri uygula
            processed_prompt = apply_dynamic_data(original_prompt, request.dynamic_data)
            print(f"ğŸ“ Dinamik veriler uygulandÄ±: {processed_prompt[:100]}...")
            
            # Ã–nceki adÄ±mÄ±n sonucunu ekle
            if current_content:
                processed_prompt += f"\n\nÃ–nceki adÄ±mÄ±n sonucu:\n{current_content}"
            
            # AI ayarlarÄ±nÄ± belirle (Ã¶zel config varsa onu kullan, yoksa prompt'a Ã¶zel)
            ai_settings = prompt_data.get("ai_settings", {
                "model": "gemini-2.5-flash",
                "temperature": 0.7,
                "top_p": 0.7,
                "response_mime_type": "text/plain",
                "max_tokens": 8192
            })
            
            if f"step_{step}" in request.custom_ai_configs:
                # Ã–zel config kullan
                custom_config = request.custom_ai_configs[f"step_{step}"]
                ai_settings.update(custom_config)
                print(f"âš™ï¸ Ã–zel AI config kullanÄ±lÄ±yor: {ai_settings}")
            elif "ai_settings" in prompt_data:
                # Prompt'a Ã¶zel ayarlar kullan
                ai_settings.update(prompt_data["ai_settings"])
                print(f"âš™ï¸ Prompt Ã¶zel AI ayarlarÄ± kullanÄ±lÄ±yor: {ai_settings}")
            else:
                print(f"âš™ï¸ VarsayÄ±lan AI ayarlarÄ± kullanÄ±lÄ±yor: {ai_settings}")
            
            # AI ile iÃ§erik Ã¼ret
            print(f"ğŸ¤– AI'ya gÃ¶nderiliyor...")
            content = generate_ai_content(processed_prompt, ai_settings)
            print(f"âœ… AI yanÄ±tÄ± alÄ±ndÄ±: {content[:100]}...")
            results.append(content)
            current_content = content
            
            # Step detaylarÄ±nÄ± kaydet
            step_details.append({
                "step": step,
                "original_prompt": original_prompt,
                "processed_prompt": processed_prompt,
                "ai_settings": ai_settings,
                "output": content
            })
        
        # Son iÃ§eriÄŸi HTML'e Ã§evir (eÄŸer markdown ise)
        final_content = current_content
        if ai_settings.get("response_mime_type") == "text/markdown":
            final_content = markdown_to_html(current_content)
        
        return {
            "content": final_content,
            "prompt_outputs": results,
            "content_type": config.name,
            "metadata": {
                "total_steps": len(config.prompts),
                "dynamic_data_used": request.dynamic_data,
                "step_details": step_details,
                "original_prompts": config.prompts
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()

@app.post("/test-single-prompt")
async def test_single_prompt(request: PromptTestRequest):
    """Tek prompt test et - admin panel iÃ§in"""
    try:
        ai_settings = {
            "model": request.model,
            "temperature": request.temperature,
            "top_p": request.top_p,
            "response_mime_type": request.response_mime_type,
            "max_tokens": request.max_tokens
        }
        
        content = generate_ai_content(request.prompt, ai_settings)
        
        return {
            "content": content,
            "ai_settings": ai_settings,
            "success": True
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/content-types")
async def create_content_type(request: ContentConfigCreate):
    """Yeni konfigÃ¼rasyon oluÅŸtur"""
    print(f"ğŸ” Create request received: {request}")
    db = next(get_db())
    try:
        # AynÄ± isimde konfigÃ¼rasyon var mÄ± kontrol et
        existing = db.query(ContentConfig).filter(ContentConfig.name == request.content_type).first()
        if existing:
            raise HTTPException(status_code=400, detail="Bu isimde konfigÃ¼rasyon zaten var")
        
        # Yeni konfigÃ¼rasyon oluÅŸtur
        print(f"ğŸ“ Creating config: name={request.content_type}, prompts={len(request.prompts)}")
        new_config = ContentConfig(
            name=request.content_type,
            description=request.description,
            prompts=request.prompts
        )
        
        db.add(new_config)
        db.commit()
        db.refresh(new_config)
        
        return {
            "id": new_config.id,
            "content_type": new_config.name,
            "description": new_config.description,
            "prompts": new_config.prompts,
            "created_at": new_config.created_at
        }
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()

@app.put("/content-types/{content_type}")
async def update_content_type(content_type: str, request: ContentConfigCreate):
    """KonfigÃ¼rasyonu gÃ¼ncelle"""
    db = next(get_db())
    try:
        config = db.query(ContentConfig).filter(ContentConfig.name == content_type).first()
        if not config:
            raise HTTPException(status_code=404, detail="KonfigÃ¼rasyon bulunamadÄ±")
        
        # GÃ¼ncelle
        config.description = request.description
        config.prompts = request.prompts
        # default_ai_settings artÄ±k kullanÄ±lmÄ±yor
        
        db.commit()
        
        return {
            "id": config.id,
            "content_type": config.name,
            "description": config.description,
            "prompts": config.prompts,
            "created_at": config.created_at
        }
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()

@app.delete("/content-types/{content_type}")
async def delete_content_type(content_type: str):
    """KonfigÃ¼rasyonu sil"""
    db = next(get_db())
    try:
        config = db.query(ContentConfig).filter(ContentConfig.name == content_type).first()
        if not config:
            raise HTTPException(status_code=404, detail="KonfigÃ¼rasyon bulunamadÄ±")
        
        db.delete(config)
        db.commit()
        
        return {"message": "KonfigÃ¼rasyon silindi"}
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        db.close()

# Admin panel iÃ§in ek endpoint'ler
@app.post("/prompts")
async def create_or_update_prompt(request: dict):
    """Prompt oluÅŸtur veya gÃ¼ncelle - admin panel iÃ§in"""
    # Bu endpoint sadece admin panel iÃ§in, gerÃ§ekte prompt'lar content-type iÃ§inde saklanÄ±yor
    # Bu yÃ¼zden sadece baÅŸarÄ±lÄ± mesaj dÃ¶ndÃ¼rÃ¼yoruz
    return {"message": "Prompt kaydedildi", "success": True}

@app.post("/ai-configs")
async def create_ai_config(request: dict):
    """AI config oluÅŸtur - admin panel iÃ§in"""
    # Bu endpoint sadece admin panel iÃ§in, gerÃ§ekte AI config'ler content-type iÃ§inde saklanÄ±yor
    # Bu yÃ¼zden sadece baÅŸarÄ±lÄ± mesaj dÃ¶ndÃ¼rÃ¼yoruz
    return {"id": 1, "message": "AI Config kaydedildi", "success": True}

@app.post("/prompt-ai-configs")
async def create_prompt_ai_config(content_config_id: int, prompt_step: int, ai_config_id: int):
    """Prompt AI config iliÅŸkisi oluÅŸtur - admin panel iÃ§in"""
    # Bu endpoint sadece admin panel iÃ§in
    return {"message": "Prompt AI Config iliÅŸkisi oluÅŸturuldu", "success": True}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)